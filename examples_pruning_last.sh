#!/bin/bash
# Example commands showing how to use the new --pruning_last flag

echo "=== New --pruning_last Flag Examples ==="
echo ""

echo "1. Prune only the LAST 3 MLP layers with Magnitude pruning:"
echo "python main.py \\"
echo "  --model baffo32/decapoda-research-llama-7B-hf \\"
echo "  --prune_method magnitude \\"
echo "  --sparsity_ratio 0.5 \\"
echo "  --sparsity_type unstructured \\"
echo "  --pruning_last 3 \\"
echo "  --save out/magnitude_last3/"
echo ""

echo "2. Prune only the LAST 5 MLP layers with Wanda:"
echo "python main.py \\"
echo "  --model baffo32/decapoda-research-llama-7B-hf \\"
echo "  --prune_method wanda \\"
echo "  --sparsity_ratio 0.5 \\"
echo "  --sparsity_type unstructured \\"
echo "  --pruning_last 5 \\"
echo "  --save out/wanda_last5/"
echo ""

echo "3. Prune only the LAST 2 MLP layers with NeuronRank:"
echo "python main.py \\"
echo "  --model baffo32/decapoda-research-llama-7B-hf \\"
echo "  --prune_method neuronrank_unstructured \\"
echo "  --sparsity_ratio 0.5 \\"
echo "  --sparsity_type unstructured \\"
echo "  --pruning_last 2 \\"
echo "  --save out/neuronrank_last2/"
echo ""

echo "4. Compare: Prune ALL layers (normal behavior):"
echo "python main.py \\"
echo "  --model baffo32/decapoda-research-llama-7B-hf \\"
echo "  --prune_method magnitude \\"
echo "  --sparsity_ratio 0.5 \\"
echo "  --sparsity_type unstructured \\"
echo "  --save out/magnitude_all/"
echo ""

echo "=== Key Features ==="
echo "• --pruning_last X: Only prunes the last X MLP blocks"
echo "• No attention layers are pruned when this flag is used"
echo "• Works with ALL pruning methods (magnitude, wanda, neuronrank, etc.)"
echo "• For LLaMA-7B (32 layers), --pruning_last 3 means pruning only layers 29, 30, 31"
echo "• Helpful logging shows which layers are being skipped"